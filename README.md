#### RISC-V simulator
この開発物は、2023年度 CPU実験で作成したRISC-V用のシミュレータである。

以下に、その時のレポートを記す。なお、一部分は省略してある。
なお、compilerファイルにあるものは同じ班のコンパイラ係が作成したものであり、OcamlからRISC-Vのアセンブリを作るものである。

#### 目次

-  0\. [チームメンバー](#0-チームメンバー)
-  1\. [はじめに](#1-はじめに)
-  2\. [実験の目的](#2-実験の目的)
-  3\. [実験の方法](#3-実験の方法)
-  4\. [実験結果](#4-実験結果)
-  5\. [作成物の構成](#5-作成物の構成)
    -  5.1 [シミュレータ](#51-シミュレータ)
        - [シミュレータの目的](#シミュレータの目的)
        - [シミュレータの構成](#シミュレータの構成)
            - [inputs](#inputs)
            - [outputs](#outputs)
            - [assemble](#assemble)
            - [make_bin](#makebin)
            - [simulator](#simulator)
            - [find_line](#findline)
        - [シミュレータの使い方](#シミュレータの使い方)
            - [基本的な使い方](#基本的な使い方)
            - [fast_modeの場合の結果](#fastmodeの場合の結果)
            - [debug_modeの場合の結果](#debugmodeの場合の結果)
    -  5.2 [コア](#52-コア)
        - [コアの目的](#コアの目的)
        - [コアの構成](#コアの構成)
            - [IF](#if)
            - [ID](#id)
            - [EX/MA](#exma)
            - [WB](#wb)
    -  5.3 [FPU](#53-fpu)
        - [FPUの目的](#fpuの目的)
        - [FPUの構成](#fpuの構成)
            - [fadd.s, fsub.s](#fadds-fsubs)
            - [fmul.s](#fmuls)
            - [fdiv.s](#fdivs)
            - [fsqrt.s](#fsqrts)
            - [ftoi.s, itof.s](#ftois-itofs)
            - [fsgnj.s, fsgnjn.s, fsgnjx.s](#fsgnjs-fsgnjns-fsgnjxs)
            - [fmadd.s, fmsub.s, fnmadd.s, fnmsub.s](#fmadds-fmsubs-fnmadds-fnmsubs)
            - [feq.s, flt.s, fle.s](#feqs-flts-fles)
    -  5.4 [メモリ](#54-メモリ)
        - [メモリの目的](#メモリの目的)
        - [メモリの構成](#メモリの構成)
            - [キャッシュシステム](#キャッシュシステム)
    -  5.5 [コンパイラ](#55-コンパイラ)
        - [コンパイラの目的](#コンパイラの目的)
        - [コンパイラの構成](#コンパイラの構成)
            - [フロントエンド](#フロントエンド)
            - [ミドルエンド](#ミドルエンド)
            - [バックエンド](#バックエンド)
            - [Lexer](#lexer-lexpy-lexcpp-lexspecl)
            - [Parser](#parser-syntaxparsepy)
            - [Type Inference](#type-inference-syntaxinferpy)
            - [K-Normalization](#k-normalization-syntaxknormalizerpy)
            - [Closure Conversion](#closure-conversion-knormalclosureconverterpy)
            - [Inline Expansion](#inline-expansion-closureinlinepy)

-  6\. [自身の作成物における工夫点](#6-自身の作成物における工夫点)
    - [アセンブラにおける工夫](#アセンブラにおける工夫)
    - [シミュレータにおける工夫](#シミュレータにおける工夫)
        -   [FPUシミュレータの実装](#fpuシミュレータの実装)
        -   [キャッシュシミュレータの実装](#キャッシュシミュレータの実装)
        -   [実行時間予測の実装](#実行時間予測の実装)
            -   [実行時間予測のアルゴリズム](#実行時間予測のアルゴリズム)
            -   [予測結果と実際の実行結果の比較](#予測結果と実際の実行結果の比較)
    -   [その他の工夫](#その他の工夫)
        - [シミュレータの機能拡張](#シミュレータの機能拡張)
        - [デバッグのしやすさの向上](#デバッグのしやすさの向上)
-  7\. [考察](#7-考察)
    - [シミュレータの実行速度について](#シミュレータの実行速度について)
        - [シミュレータのコードサイズを小さくする](#シミュレータのコードサイズを小さくする)
        - [命令実行アルゴリズムを変更する](#命令実行アルゴリズムを変更する)
        - [より高速な言語を用いる](#より高速な言語を用いる)
    - [コアの実行速度について](#コアの実行速度について)
        - [キャッシュの応答時間](#キャッシュの応答時間)
        - [コアのステージ設計](#コアのステージ設計)
        - [コアのstallの仕組み](#コアのstallの仕組み)
        - [分岐予測の採用](#分岐予測の採用)
-  8\. [参考文献](#8-参考文献)
-  9\. [実験に関する感想](#9-実験に関する感想)
-  10\. [謝辞](#10-謝辞)


#### 0. チームメンバー

略

#### 1. はじめに
<span>　</span>この度は半年間にわたるCPU実験において、シミュレータ係として参加させていただき、本当にありがとうございました。この実験を通して、CPUの基本的な動作原理を理解することができ、また、それを実際にプログラムとして実装することで、それをより深く理解することができました。また、それに加えて、チームで協力して、それぞれの役割を果たすことで、第一回発表会に間に合うことは叶いませんでしたが、第二回発表会において完動できたという成果を得ることができました。この報告書では、その成果を報告し、また、その過程で得た知見について述べたいと思います。

#### 2. 実験の目的
この実験の目的は、以下のようになっている。
- 各班で、班のオリジナルCPUを設計する
- 指定されたOcaml言語のminrt.mlを、班のオリジナルCPU上で実行する
- そのために、minrt.mlをアセンブリ言語にコンパイルするコンパイラを作成する
- また、班のオリジナルCPUと同じ命令セットを持つシミュレータを作成し、そのシミュレータ上でアセンブリ言語を実行し、その出力結果が班のオリジナルCPU上で実行した結果と一致することを確認する
- 加えてシミュレータはキャッシュメモリの統計データを取得し、FPGA実装されたCPUの実行時間を、誤差3%以内で予測する

#### 3. 実験の方法
この実験の方法は、以下のようになっている。
- まず、minrt.mlをアセンブリ言語にコンパイルし、コアに実行可能なバイナリを作成する
- 与えられたserver.pyなどを用いて、FPGA実装されたCPU上で実行し、その実行時間を計測する
- その実行時間を予測するために、シミュレータを用いて、その実行時間を予測する

#### 4. 実験結果
この実験の結果は、以下のようになっている。
<br><center>

| 実験内容 | 結果(256*256) | 結果(512*512) |
|---|---|---|
| 実行命令数 | 9097128998 回 | 31704361212 回 |
| 実行時間 | 259.5305 s | 898.8968 s |
| 予測した実行時間 | 255.031 s | 883.415 s |
| 実行時間の誤差 | 1.73371 % | 1.72231 % |
| キャッシュの総アクセス数 | 3834717178 回 | 13378170191 回 |
| キャッシュのhit回数 | 3804992187 回 | 13270438422 回 |
| キャッシュのmiss回数 | 29724991 回 | 107731769 回 |
| キャッシュのhit rate | 0.992248 % | 0.991947 % |

<br></center>

<newline><center>
![](pic/out_256P6.png)
得られた画像
<newline></center>

<span>　</span>以上のような結果が得られた。この結果から、実際の実行時間と予測した実行時間がほぼ一致しており、誤差が3%以内という目的を果たしていることが確認される。また、得られた画像から、正しくminrt.mlが実行されたことがわかり、またこの出力結果とシミュの結果が完全に一致したため、全ての目的を果たしていることが確認された。

#### 5. 作成物の構成
今回の実験では、RISC-Vの命令セットをベースに、入出力命令を加えたものを採用した。
具体的には、以下の３命令を追加した。

```
cin.int x0      // 4byteの整数入力を整数レジスタx0に格納する
cin.float f0    // 4byteの浮動小数入力を浮動小数点レジスタf0に格納する
out x0          // 整数レジスタx0の、下位8bitを出力する
```

そしてその命令セットを利用したシミュレータ、コア、FPU, メモリ, コンパイラを作成した。それぞれの構成について以下に説明する。
#### 5.1 シミュレータ
- #### シミュレータの目的
    <span>　</span>今回のシミュレータの主な目的は、コンパイラから受け取ったアセンブリを機械語に変換したものが、コアを模したプログラムにて実行できることを確認し、かつその正当性を保証したうえで、コアにその実行可能なバイナリを渡すことが主な目的である。またその時、コアのみでは簡単に取得できない情報をシミュレータを通して取得することも目的とする。
- #### シミュレータの構成
    <span>　</span>以上の目的を達成するために、今回のシミュレータは以下のような構成になっている。なお、使用した言語は全てC++である。
    ![](simu10.png)
    <center>図1: シミュレータの構成</center>
    <br>
    ファイルの構成は以下のようになっている。

    ```
    simu
    ├── assemble_and_simu
        ├── inputs
            ├── main.s
            ├── contest.sld
            ├── main_init.s
            ├── main_lib.s
        ├── outputs
            ├── core.s
            ├── core.bin
            ├── core_disassemble.txt
            ├── debug.txt
            ├── out.ppm
            ├── line_count.txt
        ├── assemble
            ├── ...
        ├── make_bin
            ├── ...
        ├── simulator
            ├── ...
        ├── find_line
            ├── ...
        ├── README.md
        ...
        ...
        ...
    ```

    それぞれのファイルについて以下に説明する。
    - #### `inputs`:
        <span>　</span>今回、シミュレータに入力するアセンブリファイルとsldファイルを格納するディレクトリである。
        `main.s`には、コンパイラから受け取ったアセンブリが格納され、`contest.sld`には今回使用するsldファイルが格納される。`main_init.s`はコアの初期化を行うアセンブリが格納され、`main_lib.s`はコンパイラが用いるライブラリ関数が格納される。
        <span>　</span>今回の実験を行う上では、`main.s`を変更することで、シミュレータに入力するアセンブリを変更することができる。他のアセンブリについては、すでに決まっているため基本的に変更することはない。
    <newline>
    - #### `outputs`:
        <span>　</span>今回のシミュレータの出力を格納するディレクトリである。`core.s`には、3つのアセンブリを一つにまとめられたものが格納され、`core.bin`には、`core.s`を機械語に変換したものが格納される。`core_disassemble.txt`には、`core.bin`を逆アセンブリしたものが格納される。`debug.txt`には、実行途中のデバッグ情報が格納される。`out.ppm`には、シミュレータの実行結果が格納される。`line_count.txt`には、`core.s`の各行に対して、実行中にどの行が何回実行されたかを記録したものが格納される。
        <span>　</span>なお、ここで生成された`core.bin`が、コア上で実行可能なバイナリそのものとなる。
    <newline>
    - #### `assemble`:
        <span>　</span>アセンブリを機械語に変換するプログラムである。このプログラムは、アセンブリを受け取り、機械語に変換したものを出力する。
        <span>　</span>動作の仕組みとしては、まず、アセンブリを受け取り、それをトークンに分割する。その後、それぞれのトークンに対して、それがどのような命令であるかを判別し、それに対応する機械語に変換する。この時、ラベルが使用されているときは、後に代入するとして、別のリストに格納する。そしてすべての命令、ラベルが読み込まれたのち、順番にラベルに代入されるようにしている。そうして全ての命令が機械語に変換された後、それを命令部分、データ部分に分け、それぞれの部分を16進数に変換し、それを出力する。
        <span>　</span>加えて、このプログラムは各機械語が何行目のアセンブリに対応するかを記録する。この情報を`pc_line.txt`に出力し、それを後術する`find_line`で利用する。
    <newline>
    - #### `make_bin`:
        <span>　</span> `assemble`ファイルによって生成された機械語をバイナリに変換するプログラムである。このプログラムは、機械語を受け取り、それをバイナリに変換したもの(core.bin)を出力する。この`core.bin`の中身は、コア上で実行可能なバイナリそのものである。また、`core.bin`の元となったアセンブリを`core.s`としている。これによって、デバッグがしやすいようになっている。
    <newline>
    - #### `simulator`:
        <span>　</span> `core.bin`を実行するプログラムである。このプログラムの基本的な動作は、`core.bin`を受け取り、それを実行した結果を`out.ppm`に出力する。それに加えて、実行中のデバッグ情報を`debug.txt`に、各命令が何回実行されたかを`pc_count.txt`に、また、`core.bin`の逆アセンブリを`disassemble.txt`に出力する。これらの情報は、コアのみでは簡単に取得できない情報であるため、シミュレータを通して取得することが目的である。また、これを後述する`find_line`を用いて、各命令が`core.s`で何行目のアセンブリに対応するかを記録する。これによって、デバッグ情報を見る際に、機械語の命令がどのアセンブリに対応するかを簡単に知ることができる。
    <newline>
    - #### `find_line`:
        <span>　</span> `core.bin`の各命令が`core.s`の何行目のアセンブリに対応するかを記録するプログラムである。このプログラムは、`assemble`から受け取った`pc_line.txt`を受け取り、その情報をもとに`simulator`から受け取った情報を整形し、`line_count.txt`などとして出力する。これによって、`core.bin`の各命令が`core.s`の何行目のアセンブリに対応するかを簡単に知ることができる。

- #### シミュレータの使い方
    <span>　</span>今回のシミュレータの使い方は、詳しくは`README.md`に記載されているが、以下に基本的な使い方について説明する。
    - #### 基本的な使い方

        1. `assemble_and_simu`ディレクトリに移動する
        2. `inputs`ディレクトリに、コンパイラから受け取ったアセンブリを`main.s`として格納する
        3. `inputs`ディレクトリに、今回使用するsldファイルを`contest.sld`として格納する
        4. コンパイラ係などが、実行結果を速く知るためにfast_modeを実行したいときは
            ```
            ./fast.sh
            ```
            を、コア係などが実行結果を詳しく知るためにdebug_modeを実行したいときは
            ```
            ./debug.sh
            ```
            を実行する。
            <newline>
            また、それぞれのモードにおいて、サイクル"from_cycle"から"to_cycle"の間の実行過程のデバッグ情報`debug.txt`を見たいときは、
            ```
            ./print_fast.sh <from_cycle> <to_cycle>
            ```
            または
            ```
            ./print_debug.sh <from_cycle> <to_cycle>
            ```
            を実行することで、その情報を見ることができる。
        5. `outputs`ディレクトリに、`out.ppm`などの実行結果が格納され、実行命令数、最後に実行された行数などが標準出力される。

        <br>
    <span>　</span>なお、標準出力については、以下のようになっている。なお、以下は例として、レイトレの256*256の画像を生成する場合の標準出力である。画像サイズを変更したいときは、`inputs/main.s`の258行目と260行目の数字を変更することによって可能である。

    -   #### `fast_mode`の場合の結果

        ```
        time : 1152472231574 nsec, 1152472 msec
        pc : -1
        EX_count : 9097128998
        sec_of_data : 3.26724 sec
        Return Code : 6
        Max_stack: 3fffde0
        Max_heap: 108f984
        Mips: 7.89358 Mips

        Done.

        Last line: 1497
        ```

    -   #### `debug_mode`の場合の結果

        ```
        time : 2985529721566 nsec, 2985529 msec
        pc : -1
        EX_count : 9097128998        
        sec_of_data : 3.26724 sec    
        stall_cycle_of_data_section : 582 cycle
        sec_of_stall_of_data_section : 7.25686e-06 sec
        stall_cycle_of_cin : 2098102 cycle
        sec_of_stall_of_cin : 0.0261609 sec

        cycle (Dependency Optimization) : 14101626077
        (Estimated execution time : 175.831 sec)
        (Estimated sum of time: 179.098 sec)
        stall (Dependency Optimization) : 827543620

        cycle (No Dependency Optimization) : 20191482052
        (Estimated execution time : 251.764 sec)
        (Estimated sum of time: 255.031 sec)
        stall (No Dependency Optimization) : 4923644961

        total_cache_access: 3834717178
        cache_hit: 3804992187        
        cache_miss: 29724991
        hit rate: 0.992248
        flush: 870495809
        Return Code : 6
        Max_stack: 3fffde0
        Max_heap: 108f984
        Mips: 3.04707 Mips
        clock_rate: 4.72332 MHz      

        Done.

        Last line: 1497
        ```

        それぞれのmodeにおいて、実行時間、実行命令数、最後に実行された行数などが標準出力される。また、`debug_mode`の場合には、さらに、様々な場合の実行時間の推定値、キャッシュのhit rate、などが標準出力される。
    
    <br>
    <span>　</span>以上のようにすることで、シミュレータを用いて、コンパイラから受け取ったアセンブリを機械語に変換し、それを実行し、様々な情報を取得することができるという目的を果たすことができる。

    <br><newline>
    
    <span>　</span>(なお、提出ファイルには実行ファイルも含まれており、実行環境は"Ubuntu 22.04.3 LTS"を想定している。実行できない場合は、`./make.sh`を実行することで、全てのプログラムを再コンパイルすることができる。コンパイルにはgccによる`g++`を想定している。)

#### 5.2 コア

略

#### 5.3 FPU

略

#### 5.4 メモリ

略

#### 5.5 コンパイラ

略

#### 6. 自身の作成物における工夫点
<span>　</span>今回自分はシミュレータ係を担当した。以下に、自分の作成物における工夫点について述べる。

- #### アセンブラにおける工夫
    <span>　</span>今回のアセンブラでは、なるべくシンプルな構造とするために、アセンブリ１行に対して、疑似命令も含め機械語の命令数は、ラベルの位置に関わらず、一定としている。(例えば、li命令に関しては、即値のみをレジスタにロードする命令であるが、これを即値の大きさによって `"addi"` 命令と `"lui"` 命令に分解することで、li命令を実装している。)
    <newline>
    <span>　</span>これはつまり、各命令の命令メモリにおけるアドレスが前から順番に決まることが保証されるが、例えば　`"blt"`　のような分岐命令に対して、ラベルが遠すぎるとき、2命令にしなければならないときを、想定しないことを意味する。(今回のプログラムでは、エラーを出し止まるようになっている。)
    <span>　</span>しかし、普通のアセンブリ言語において、このようなことはほとんどないこと、またこのようにすることで、ラベルの指すアドレスも固定値となり、アセンブリの行数 $n$ に対して、計算量が$O(n)$ となることから、このような構造を採用した。
    <newline>
    <span>　</span>実際このアセンブラは実験の発表会前日まで特に問題はなかったが、発表会当日になって、コンパイラ係がインライン展開したアセンブリを出し、その中でいくつかの `"blt"` のラベルが4104ほど遠いという問題が起きた( `"blt"` で許されるのは相対距離が4096以下である必要がある)。
    <span>　</span>この問題は、アセンブラの構造上、解決するには、アセンブリを読み込む際に、各命令、各ラベルの位置を記録し、アドレスがずれたものすべてに対して、それを修正するという作業を毎回行う必要がある。このようなことを行うと、アセンブリの行数 $n$ に対して、計算量が最悪$O(n^2)$ となるため、どうしようかと思案したが、今回のプログラムではそのような問題となる命令は `"blt"` のみであったため、 `"pre_assemble"` というプログラムを作成し、その中で、アセンブラに送る前の前処理として、 `"blt"` のラベルが4096以上離れているものを探し、それを `"bge ..., 8 "` , `"j Label"` に置き換えるという、下図のようにアセンブラの構成を少し変更するという方法を取った。これにより、 `"blt"` のラベルが4096以上離れているものがなくなり、 `"assemble"` によって機械語に変換することができるようになった。
    <newline>
    <span>　</span>以上のような工夫をすることで、問題を解決し、かつ計算量も抑えることができた。
    
    <br>

    ![pre_assemble](pre_assenble.png)
    <center>図6: pre_assembleの構成</center>
    <br>

- #### シミュレータにおける工夫
    <span>　</span>今回自分が作成したシミュレータでは、まず単位取得要件を満たすために、
    - FPUシミュレータの実装
    - キャッシュシミュレータの実装
    - 実行時間予測の実装
    
    の3点について工夫を行った。それぞれについて以下に述べる。

    - #### FPUシミュレータの実装
        <span>　</span>今回のシミュレータ内のFPU演算は、まずはFPU係の人と話し合い、その構造を共有し、実際にFPUの構造を理解した上で、実装を行った。具体的には、先輩方が残してくれたFPUの資料を参考にしつつ、各演算によって適切に変更を加えた。実際のFPU演算の構造は前章で述べた通りである。また、自分はC++で、FPU係はVerilogで実装した後、自分がVerilogのテストベンチを作成し、それを用いて、自分のシミュレータとFPU係のシミュレータの結果をランダムに比較する `"simulator/fpu_test_v2"` というディレクトリを作成し、その中でシェルスクリプトを書くことで、各演算においてランダム500万回のテストと、コーナーケースのテスト100万回を行い、その結果を比較した。これによって、FPU構造のいくつかの問題点を発見しつつ、最終的にきちんと指定された誤差範囲内に収まるようなFPUを実装し、かつシミュレータと結果が一致することを確認することができた。
        <span>　</span>なお、`"simulator/fpu_test_v2"`は、例えばfmul.sを調べたいときは、`"simulator/fpu_test_v2/main.cpp"`の783行目と784行目の関数名をそれぞれ `"FPUfmul"` , `"fmul"` に変更し、その後`"simulator/fpu_test_v2/verilog/fmul"`に移動し、`"./a.sh"`を実行することで、テストを行うことができる。

    - #### キャッシュシミュレータの実装
        <span>　</span>今回のシミュレータ内のキャッシュは、最初の段階でライトバック、ライトアロケート形式で、LRUを用いて置換を行うset-associativeで実装するとメモリ係と話していたので、それに従って実装を行った。ただ、ウェイ数やラインサイズはまだその段階では決まっていなかったので、そこは可変となるようにうまく実装した。特に、LRUの動作について、ナイーブに実装すると計算量がウェイ数 $n$ と比例してしまうが、Hash Mapと連結リストを用いることで、計算量を $O(1)$ に抑えることができた。また、動作をうまく再現したため、キャッシュへのアクセス数やヒット率が正しく計算されることを確認することができた。
        <span>　</span>以上の工夫により、キャッシュシミュレータの実装を行うことができた。実際、ライン数やウェイ数を可変にしたため、どの値が最適かを探すことができた。
        <newline>
        <span>　</span>ただ、今回はLRUの動作について、計算量を $O(1)$ に抑えることができたが、結果としてウェイ数は $2$ であり、かつHash Mapは定数倍が重いため、ナイーブに実装するよりも計算量が増えてしまった。計算量を抑えるアルゴリズムは、ある程度の数の大きさがないと、逆効果になってしまうことがあるということがわかった。

    - #### 実行時間予測の実装
        - #### 実行時間予測のアルゴリズム
            <span>　</span>今回の実験の目的の一つとして、コアの実行時間を予測することがある。実行時間はコアのサイクル数を取得すれば、それにクロック数をかけることで求めることができる。そこで、コアの動きを再現しているdebug_modeを用いて、実行時間を予測した。動きを再現するとき、以下のことに注意する必要がある。
            <br>
            - キャッシュの動作を再現する。特に、キャッシュミスが起きたときの遅延サイクルを再現することが重要である。
            - stall, flushの動作を再現する。今回のコアでは、分岐予測はせず、命令によらずその実行が終わるまでstallするような構造になっているため、これを再現することが重要である。
            - 入出力の遅延時間を再現する。特に、今回は入力のための命令列やsldファイルが大きく、また入力は初めにまとめて行われるため、それによる遅延サイクルを再現することが重要である。出力に関しては、今回の実験では実行中に並行して分散して行われるため、それによる遅延サイクルはほとんどないと考えられるため、それを再現する必要はないとした。

            <br>
            <span>　</span>以上のようなことを考慮することで、コアの実行時間を予測することができる。

            <span>　</span>具体的な遅延サイクルの式は以下のようになる。
            <br>

            - キャッシュについて:
                <span>　</span>キャッシュミスが起きたとき、ライトバックが必要な時は、clock_rate(MHz)に対して、
                ```
                cache_miss_time_wtb = (0.6 * clock_rate + 31.7)
                ```
                ライトバックが必要ないときは
                ```
                cache_miss_time_no_wtb = (0.39 * clock_rate + 21)
                ```
                とする。また、キャッシュミスが起きないときは、1サイクルであるとする。
            - stall, flushについて:
                <span>　</span>stallは、コアの説明にもある通り、各命令に対して、その実行が終わるまでstallするため、その命令の実行サイクル数をそのまま遅延サイクル数とする。(例えば、`fadd.s`命令は2サイクルであるため、stallは2サイクルである。)
                <span>　</span>ただし、今回のシミュレーターには、ステージ間のハザードによるstallも検出することができるため、今回の実験には結果的に必要ないが、比較のためにその場合の遅延サイクル数も計算した。
                <span>　</span>flushは、分岐が成立したとき、その分岐が成立した命令以降の命令を全てflushするため、そのflushされたステージ分の遅延サイクル数を加える。
            - 入出力について:
                <span>　</span>入出力については、今回の実験で使用するUARTの遅延サイクル数を用いて、それを加える。送信するデータ1byteにつき、
                ```
                clock_per_1byte_data ​= CLK_PER_HALF_BIT + CLK_PER_BIT*9
                ```
                と計算され、その遅延サイクル数を加える。
            <br>
            
            <span>　</span>以上のようなことを考慮することで、コアの実行時間を予測することができる。
            <span>　</span>ただし、ここで一つ注意すべきことは、今回のシミュレータは一般的なコアの構造であるIF, ID, EX, MEM, WBの5ステージパイプラインを持っているが、今回のコアは構造がIF, ID1, ID2, EX/MEM, WBとなっていることである。この差は、コア係が最後にアーキテクチャを大きく変えたことが原因であるが、今回のコアはステージ間のハザードによるstallがないため、命令の種類のみを考慮すればよくうまく対応ができた。ただ、flushの際にシミュレータのよりもさらにもう一つ分のステージをflushする必要があるため、対応策としてflush 1回につき 1つの遅延サイクル数を加える必要がある。これによって、コアの実行時間を予測することができる。

            <br>

            <span>　</span>このような工夫により、debug_modeを用いて、実行時間を予測することができた。実際に実行したとき、実行時間に関するデータが以下のように得られる。

            ```
            sec_of_data : 3.26724 sec    
            stall_cycle_of_data_section : 582 cycle
            sec_of_stall_of_data_section : 7.25686e-06 sec
            stall_cycle_of_cin : 2098102 cycle
            sec_of_stall_of_cin : 0.0261609 sec

            cycle (Dependency Optimization) : 14101626077
            (Estimated execution time : 175.831 sec)
            (Estimated sum of time: 179.098 sec)
            stall (Dependency Optimization) : 827543620

            cycle (No Dependency Optimization) : 20191482052
            (Estimated execution time : 251.764 sec)
            (Estimated sum of time: 255.031 sec)
            stall (No Dependency Optimization) : 4923644961
            ```

            <span>　</span>sec_of_dataは今回の実行バイナリを送信するのにかかる時間であり、sec_of_stall_of_data_sectionはデータセクションのデータをキャッシュにloadするのにかかる時間である。sec_of_stall_of_cinはsldファイルを読み込む際のstallにかかった時間であり、cycle (Dependency Optimization)はコアがステージ間のハザードのみに対してstallする場合のサイクル数であり、cycle (No Dependency Optimization)は今回のコアのように、ハザードに関係なく命令の実行時間によってstallする場合のサイクル数である。
            <span>　</span>今回のコアは後者であるため、上の実行結果の `"255.031 sec"` が、実際の実行の予測時間となる。

        - #### 予測結果と実際の実行結果の比較
            <span>　</span>以上のような方法で、実行時間を予測することができた。実際に実行したとき、実行時間に関するデータが以下のように得られた。

            <br><center>

            | 画像サイズ | 実際の実行時間 (sec) | 予測時間 (sec) | 誤差率 (%) | 差分 (sec) |
            | :---: | :---: | :---: | :---: | :---: |
            | 1*1 | 3.5634 | 3.37090 | 5.402% | 0.19250 |
            | 2*2 | 3.5802 | 3.38345 | 5.496% | 0.19675 |
            | 4*4 | 3.6918 | 3.49652 | 5.290% | 0.19528 |
            | 8*8 | 4.3003 | 4.09023 | 4.885% | 0.21007 |
            | 16*16 | 6.1554 | 5.91277 | 3.942% | 0.24263 |
            | 32*32 | 11.9948 | 11.6586 | 2.803% | 0.33620 |
            | 64*64 | 29.4193 | 28.775 | 2.190% | 0.64430 |
            | 128*128 | 87.9787 | 85.8361 | 2.435% | 2.1426 |
            | 256*256 | 259.5305 | 255.031 | 1.734% | 5.2135 |
            | 512*512 | 898.8968 | 883.415 | 1.722% | 15.4818 |
            
            図7: 予測結果と実際の実行結果の比較
            <br></center>

        <span>　</span>上の表のように、実際の実行結果と予測結果を比較すると、サイズが32 * 32以上のものは、誤差率が約3%ほどと、高い精度で予測することができた。特に、サイズが256 * 256の時には、誤差率が約1.7%ほどと、非常に高い精度で予測することができた。
        <span>　</span>サイズが小さいものでは5%ほどとなってしまった原因としては、実行時間のほとんどがデータの送信が実行時間の大半を占めており、データの送信においてのコアの理論はあっていると考えられるが、server.pyの送信の仕様や測定誤差が相対的に大きくなってしまうためと考えられる。server.pyの送信にかかる時間を別で計測し、それを加えることを考えたが、今回の実験の目的はあくまで自作CPUの実行時間を予測することであるため、それは行わなかった。

- #### その他の工夫

    <span>　</span>上記のような工夫以外にも、他の班員からの要望に応じるなどして、以下のような工夫を行った。
    -   #### シミュレータの機能拡張
        <span>　</span>シミュレータに関しては、他の班員からの要望に応じて、様々な機能を追加した。先述のシミュレータの構造にも記載されているものもあるが、具体的には以下のような機能が搭載されている。
        <br>
        - `core.bin`など、コアで実行可能なバイナリファイルを直接読み込むことができる
        - 命令ファイルはバイナリファイルの他に、2進数、16進数でも、txtファイルや標準入力からでも読み込むことができる
        - 読み込んだ命令列のの逆アセンブリを出力する
        - アセンブリの各行の命令が何回実行されたかを記録する
        - 任意のサイクルの実行過程を出力する
        - レジスタの値や各ステージの挙動など、コアの動きを可視化する
        - 分岐予測(Bimodal Predictor, Adaptive Branch Prediction, Gshare Predictor)​の動作を再現する
        - キャッシュの統計情報の取得
        - メモリの統計情報の取得
        - メモリアクセスにおいて、どのアドレスがどのようにアクセスされたか、また最後にアクセスされたサイクルがいつかを取得する
        - コアのパイプライン実行を模したdebugモードの実行
        - コンパイラ係専用の、様々な統計情報を取得しない代わりに、実行速度を重視したfastモードの実行
        - 各サイクルにおけるfowarding, stall, flushの情報を取得する
        - stack, heap領域が最大でどれだけ使われたかを取得する
        - pcやレジスタなど、各値を10進数だけでなく、16進数でも表示する

        <br>
        <span>　</span>以上のように、このシミュレータは、様々な機能を搭載しており、コアのみでは簡単に取得できない情報を取得することができる。またその分、実行速度は遅くなるという問題が発生したために、fastモードを実装することで、実行速度を重視した実行も可能となっている。
        <span>　</span>ただ、機能を増やしすぎたがゆえに、またかえって使いにくくなっていたようだったので、そこはシェルスクリプトを用いて、それぞれの機能を簡単に実行できるようにしている。なので、使う分には先述の[シミュレータの使い方](#シミュレータの使い方)使い方に従えばよい。それでもそれぞれの機能を使いたい場合は、使い方の詳細については、`README.md`に記載されているため、そちらを参照することをすすめる。
    -   #### デバッグのしやすさの向上
        <span>　</span>今回のシミュレータでは、最初は正しい命令に対して正しい結果が出ることを重視していたため、デバッグのしやすさはあまり考慮していなかった。しかし、実際に実行すると、コンパイラ係が例えばレジスタ割り当てに失敗して正しくない命令が生成された場合や、コア係が実際に実行してうまくいかなかったとき、うまくいかなかったサイクルがわかっても、その原因となる具体的なアセンブリの部分を特定することが非常に難しいことがわかった。そこで、シミュレータの機能を拡張することで、デバッグのしやすさを向上させることを考えた。具体的には、以下のような機能を追加した。なお、いくつかは先ほどの機能拡張にも含まれているが、ここでは特にデバッグのしやすさを向上させるために追加したものについて述べる。
        <br>
        - `find_line` というプログラムを作成し、それを用いることで、シミュレータのデバッグ情報に、各命令がアセンブリのどの行に該当するかを追加するようにした
        - 最後に実行された命令がアセンブリのどの行に該当するかを取得する
        - メモリアクセスにおいて、アクセスされたアドレスを16進数表示し、かつそのアドレスに最後に書き込んだサイクルを取得する
        - 各サイクルごとに、命令としては正しいが挙動としてはおかしいかを判定し、おかしい場合は停止してその命令を出力するようにした
            - 具体的には、奇数アドレスへのアクセスや、スタックポインタやヒープポインタの値がおかしい場合などを判定するようにした

        <br>
        <span>　</span>これらの機能を追加することで、デバッグのしやすさを向上させることができた。特に、今までは命令の内容とメモリの位置からアセンブリのどの行に該当するかを推測する必要があったが、それが不要になったことで、デバッグのしやすさが向上したと考えられる。実際に、これらの機能を用いて、コンパイラ係やコア係が問題を特定するのにとても役立ったという感謝の報告があった。シミュレータ係としては、このような報告を受けることができて、とても嬉しかった。

    <br>
    <span>　</span>以上のような様々な工夫を行うことで、自分の作成物において、単位取得要件を満たすだけでなく、他の班員からの要望にも応え、班の完動に貢献することができたと考えられる。
        

#### 7. 考察
<span>　</span>ここまで、自作CPUの構成やシミュレータを実装するにあたっての工夫について述べてきたが、ここでは、それについての考察を述べる。

-   #### シミュレータの実行速度について
    <span>　</span>今回作成したシミュレータは、fast_modeでは8 Mips、debug_modeでは2.5 Mips程度と、実行時間が遅いという欠点がある。debug_modeでは情報を多く集めるため、遅くなるのは仕方のないことだが、fast_modeはもう少し速いほうが望ましい。よってここでは、実装する中で考えた、より速くするためにはどうすればよかったかについて述べる。
    -   #### シミュレータのコードサイズを小さくする
        <span>　</span>今回のシミュレータのコードサイズは合計約4000行と、とても大きなものになってしまった。これは、シミュレータの機能が多いこと、また私の書くコードが冗長であったことが原因である。コードの量が多いと、コンパイラによる最適化が難しくなること、またコードが長すぎるということはコンパイルした際にアセンブリの量が長くなるということであり、実験の中でも実感したが、アセンブリの量が冗長に長いと、分岐命令やジャンプ命令が1命令ではなく、2命令以上になってしまい、それによって実行命令数が増えてしまうことがあり、実行時間を遅くしてしまうことがある。
        <span>　</span>そこで考えられるその解決策としては、fast_modeとdebug_modeのファイルを完全に別にするということが考えられる。これによって、fast_modeの際のコードサイズが小さくなり、実行時間が早くなると考えられる。また、シミュレータの機能について、今回は標準入力から分岐予測や、コアの状態の可視化などの機能を追加したが、それらも標準入力ではなく、コードに `"define"` などをを用いて、使いたい機能の選択したうえで毎回コンパイルすることで、最適化によって無駄な比較命令を減らし、実行時間を短くすることができると考えられる。
    -   #### 命令実行アルゴリズムを変更する
        <span>　</span>今回のシミュレータは、コアの動きを再現することを重視していたため、fast_modeでもEXステージの動きを再現し、1サイクルにつき1命令を実行するようにしていた。しかしここにおいて、fast_modeではコアの動きを模す必要はなく、実行結果が一致していればよいため、命令実行の仕組みを高速化することができる。例えばラベル間の命令の順序は基本的に変わらないことを利用し、EXステージの動きを再現せず、複数の命令をまとめて実行するという方法を採用することで、実行時間を短くすることができると考えられる。ただし、この方法は、コアの動きを再現することをやめるため、デバッグのしやすさが損なわれるという点を考慮する必要がある。
    -   #### より高速な言語を用いる
        <span>　</span>今回のシミュレータはC++を用いて実装したが、C++は高速な言語であるとはいえ、最速ではなく、それよりも高速な言語がある。そのため、より高速な言語を用いることで、実行時間を短くすることができると考えられる。具体的には、C++よりも高速な言語として、RustやGoなどがある。特にRustは、C++と同じくらいの実行速度を持ちながら、安全性が高いという特徴があるため、それを用いることで、実行速度を短くすることができると考えられる。実際に、他の班ではRustで実装した班があり、その班のシミュレータはC++で実装したシミュレータよりも実行速度が速かったという報告があった。

    <br>
    <span>　</span>以上のような方法を用いることで、シミュレータの実行速度を向上させることができると考えられる。またこのような長いコードを書くする際には、これらのような最適化を考えて実装したいと思う。

-   #### コアの実行速度について
    <span>　</span>自分はコアの設計には関わっていないため、コアの実行速度についてはあまり詳しくはないが、シミュレータ目線から、コアの実行速度についても考察する。というのも、今回私たちの班はのコンパイラ係は、実行命令数が約90億回と、他の班に比べてそこまで多いわけではないが、それでも実行時間が約250秒と、命令数の割には実行時間が長いという問題があったためである。(参考に、他のある班は実行命令数が40億程度であったが、実行時間が約60秒程度であった。命令数は約2倍だが、実行時間は4倍となってしまっている)
    <span>　</span>その原因について、以下のようなことが考えられる。

    -   #### キャッシュの応答時間
        <span>　</span>発表会時も高前田先生から指摘されたが、キャッシュの応答時間が遅いことが原因であると考えられる。キャッシュヒット時は1サイクルで返ってきて一般的であるが、キャッシュミス時は80サイクルほどと、一般的な応答サイクルが1,2桁ほどであるのに対して、とても遅くなってしまっている。そのため、キャッシュミスが多いと、実行時間が遅くなってしまうと考えられる。特に、今回のコアはキャッシュミスの回数が多いため、実行時間が遅くなってしまったと考えられる。
        <span>　</span>この原因についてメモリ係は、実装が冗長となり、無駄な待機時間が多くなってしまったからであると述べていた。詳しい考察はメモリ係のレポートに譲るが、例えばこれを50サイクルにすると、[シミュレータの統計情報](#debugmodeの場合の結果)のキャッシュミス数から約860万サイクルほどの短縮となる。これは、約11秒ほどの短縮となるため、実行時間を短縮するためには、キャッシュの応答時間を短縮することが有効であると考えられる。

    -   #### コアのステージ設計
        <span>　</span>今回のコアは、IF, ID1, ID2, EX/MEM, WBという5ステージパイプラインを持っているが、これは一般的なコアの構造の IF, ID, EX, MEM, WBとは異なっている。この差は、コア係が最後にアーキテクチャを大きく変えたことが原因であるが、このアーキテクチャの変更はバグが生みにくいという利点がある一方で、flush時に IF, ID1, ID2 の３ステージ分の命令を消してしまうため、実行時間が遅くなってしまうという問題がある。実際、[シミュレータの統計情報](#debugmodeの場合の結果)のflushの情報から、今回のコアが一般的なアーキテクチャを採用していた場合、そのflush数である約870万サイクルほどの短縮が見込まれる。これは、約11秒ほどの短縮となるため、実行時間を短縮するためには、一般的なアーキテクチャを採用することが有効であると考えられる。

    -   #### コアのstallの仕組み
        <span>　</span>今回のコアは、ハザードに関係なく、各命令の実行完了時間になるまでstallを行う仕組みを採用しているが、このstallの仕組みを適切に変えることで、実行時間をより速くできると考えられる。そこで、例えばコアのstallの仕組みを、命令間のハザードが発生した場合のみとした場合、`"fdiv.s"`命令などを実行するとき、必ずstallが発生するのではなく、その演算結果のレジスタを使う命令が来るまでstallを行わなくてすむようになる。この場合の実行サイクルは[シミュレータの統計情報](#debugmodeの場合の結果)における`"cycle (Dependency Optimization)"`の14044711300サイクルであるため、約6000万サイクルの短縮が見込まれる。これは、約75秒ほどの短縮となるため、実行時間を短縮するためには、stallの仕組みを適切に変えることが有効であると考えられる。

    -   #### 分岐予測の採用
        <span>　</span>今回のコアは分岐予測を採用していないが、分岐予測を採用することで、実行時間を短縮することができると考えられる。実際、今回のシミュレータは分岐予測に対応しているため、仮に一番シンプルな実装であるBimodal Predictorを採用した場合、シミュレータでは以下のような結果が得られた。


        ```
        time : 2762888014774 nsec, 2762888 msec
        pc : -1
        EX_count : 9097128998        
        sec_of_data : 3.26724 sec    
        stall_cycle_of_data_section : 582 cycle
        sec_of_stall_of_data_section : 7.25686e-06 sec
        stall_cycle_of_cin : 2864450 cycle
        sec_of_stall_of_cin : 0.0357163 sec

        cycle (Dependency Optimization) : 12024760153
        (Estimated execution time : 149.935 sec)
        (Estimated sum of time: 153.202 sec)
        stall (Dependency Optimization) : 842730151

        cycle (No Dependency Optimization) : 17402042636
        (Estimated execution time : 216.983 sec)
        (Estimated sum of time: 220.25 sec)
        stall (No Dependency Optimization) : 4923644961

        total_cache_access: 3834717178
        cache_hit: 3804992187        
        cache_miss: 29724991
        hit rate: 0.992248
        flush: 172944368
        Return Code : 6
        Max_stack: 3fffde0
        Max_heap: 108f984
        Mips: 3.29262 Mips
        clock_rate: 4.35224 MHz      

        Done.
        ```

        <span>　</span>この結果より、Binary Predictorを採用した場合、実行時間が約220秒、先ほど述べたようにstallの仕組みを適切に変えた場合は実行時間が約150秒となることがわかる。これは、合計約100秒ほどの短縮となる。もちろんこの分岐予測に関しては、コアの構造がより複雑になり、クロック数がある程度小さくなることが予想されるが、その分を考慮しても、実行時間を短縮するためには、分岐予測を採用することが有効であると考えられる。

    <br>
    <span>　</span>以上のようにコアやキャッシュの構造を工夫することによって、理論上は実行時間を短縮することができると考えられる。しかし、実際には、それらの構造を変えることによって、可能なクロック数が変化したり、バグが生じてそもそも実装できない可能性があるため、あくまでシミュレータ係としての考察であることを留意する必要がある。

#### 8. 参考文献
-   [ディジタル回路設計とコンピュータアーキテクチャ, David Harris, Sarah Harris, 2012, 朝倉書店](https://riscv.or.jp/2022/05/harris-and-harris-digital-design/)

#### 9. 実験に関する感想
<span>　</span>今回私は理学部情報科学科の有名な実験であるCPU実験にシミュレータ係として参加しましたが、全体としての感想を一言でまとめるなら、とても勉強になった半年間だった、ということです。 0から自作CPUのシミュレータを実装するという経験は、Risc-Vのルールや仕組み、アセンブリの意味や使い方、またコアやFPU、キャッシュなどの構造や動作を理解するのに大変役立ちました。 また、実装する中で、普段書いているはずのC++でも、様々な便利な機能やライブラリがあることを知り、それらを使うことで、実装の効率が大幅に向上することができました。 本当にいい経験になったと思います。
<newline>
<span>　</span>また、今回の実験を通じ、グループで協力して一つのプロジェクトを進めるということの大変さを実感しました。 今回の実験は自由度がとても高かったため、それぞれが自分のペースで進めることができるという利点もありましたが、それが逆に、他の人の進捗がわからないという問題もありました。 特に、他の人が担当している仕事内容をうまく把握できていないとき、その人の進捗がどれだけ遅れているかわからないため、全体の進捗がわからなくなってしまうことがありました。 そのため、進捗をきちんと共有することの大切さを実感しました。 今回起きた問題としては、最初に決めた線表通りに進捗が進まなかったことがあります。 これは、最初に決めた線表がそもそも厳しかったこともありますが、それ以上に、進捗をきちんと共有できていなかったこと、また遅れていることの危機感が足りなかったことが原因だと考えられます。 今後、グループでのプロジェクトを進める際には、進捗をきちんと共有し、仲間が遅れているときは、それがどれくらい遅れているかをきちんと把握し、それに対して巻き取れる仕事は巻き取るなど、個人だけでなく全体の進捗を意識して進めることが大切だと感じました。 今後は、この反省を生かし、グループプロジェクトを進める際には、進捗をきちんと共有し、全体の進捗を意識して進めるようにすること、また各自の進捗について、なるべく細かく達成すべきことを決めて、こまめにどれだけやるべきことを達成できたかを確認することを心がけたいと思います。
<newline>
<span>　</span>このように、少し問題が発生したこともありましたが、それ以上に、この実験を通じて、自作CPUのシミュレータを実装するという経験は、とても勉強になった半年間でした。 また、自分はC++でこれほど大きなプログラムを実装することは初めての経験で、最初に自分のPCでシミュレータが動いたときは本当にうれしかったです。 また、自分の作成物が他の人に使われるということも初めての経験で、それが役に立ったようでとてもうれしかったです。 また似たような経験をすることがあれば、今回の反省を生かし、かつ良かった点も生かして、より良いプロジェクトを進めたいと思います。 本当にこの実験は自分にとってとても良い経験になりました。 半年間本当にありがとうございました。

#### 10. 謝辞

<span>　</span> 本実験を行うにあたり、他の班のシミュレータ係の方や、先生やTAの方々など多くの方々にご指導いただきました。ここに深く感謝いたします。また、実験の進行にあたり、同じ班の皆様にはもちろん、他の班の方々や先生やTAの方々にも多くの方々にご協力いただきました。重ねて感謝いたします。本当にありがとうございました。
<newline>
<span>　</span> また、本実験を通じて、多くのことを学ぶことができました。その中で、自分の作成物においても、様々な工夫を行うことができました。そのようなことができたのも、多くの方々のご指導やご協力があったからこそだと感じております。本当にありがとうございました。
<newline>